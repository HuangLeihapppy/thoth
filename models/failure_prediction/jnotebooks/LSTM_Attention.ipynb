{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQvr9zfcPRi-"
   },
   "source": [
    "Contributors: Rohit Singh Rathaur, Girish L.\n",
    "\n",
    "Copyright 2021 [Rohit Singh Rathaur, BIT Mesra and Girish L., CIT GUBBI, Karnataka]\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQ6lT1e2hrx4",
    "outputId": "cb071d50-8fcb-426d-8fa9-6f7033f783d1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLhroy5BnMnC"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "2-UpMVsSnfCI",
    "outputId": "120b11e9-5c7d-4332-d133-9636a8d002aa"
   },
   "outputs": [],
   "source": [
    "df_Ellis  = pd.read_csv(\"/content/drive/MyDrive/LFN Anuket/Analysis/data/Final/Ellis_FinalTwoConditionwithOR.csv\")\n",
    "df_Ellis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "92xBt43BnjAo",
    "outputId": "2104e011-6066-4e86-e6f8-515dfb9ea715"
   },
   "outputs": [],
   "source": [
    "df_Ellis.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "RSo-aa-SIoBR",
    "outputId": "ea97c36d-cb27-4fb3-d9bd-e8f1776b098d"
   },
   "outputs": [],
   "source": [
    "# we show here the hist\n",
    "df_Ellis.hist(bins=100,figsize=(20,15))\n",
    "#save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "gggaMJ_2LtFs",
    "outputId": "9e21fcc0-a838-4449-ef31-8e7d1df4d060"
   },
   "outputs": [],
   "source": [
    "cpu_system_perc = df_Ellis[['ellis-cpu.system_perc']] \n",
    "cpu_system_perc.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20) \n",
    "plt.xlabel('Timestamp', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "R_ctvXcQL1Xf",
    "outputId": "1a35f11e-eb94-4404-bd86-6f6fc2765ba2"
   },
   "outputs": [],
   "source": [
    "load_avg_1_min = df_Ellis[['ellis-load.avg_1_min']] \n",
    "load_avg_1_min.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20) \n",
    "plt.xlabel('Timestamp', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "Gkd5ecCmL6Bw",
    "outputId": "2396e496-512e-45de-b804-acfb32e79b41"
   },
   "outputs": [],
   "source": [
    "cpu_wait_perc = df_Ellis[['ellis-cpu.wait_perc']] \n",
    "cpu_wait_perc.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20) \n",
    "plt.xlabel('Year', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "EycZrQU0MBSX",
    "outputId": "dcf3d389-1ac0-4005-ae48-53e0f96548b1"
   },
   "outputs": [],
   "source": [
    "df_dg = pd.concat([cpu_system_perc.rolling(12).mean(), load_avg_1_min.rolling(12).mean(),cpu_wait_perc.rolling(12).mean()], axis=1) \n",
    "df_dg.plot(figsize=(20,10), linewidth=5, fontsize=20) \n",
    "plt.xlabel('Year', fontsize=20); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoQA_MIBMknS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "id": "Pi8UMMitMa3Q",
    "outputId": "57b8d44c-ad3d-45e0-82da-1787d6d47d55"
   },
   "outputs": [],
   "source": [
    "# we establish the corrmartrice\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "correaltionMatrice = df_Ellis.corr()\n",
    "f, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.heatmap(correaltionMatrice, cbar=True, vmin=0, vmax=1, square=True, annot=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkYwyKtXMvpy",
    "outputId": "f5386858-2a38-4b20-9be9-f841ee5af0d6"
   },
   "outputs": [],
   "source": [
    "df_Ellis.corrwith(df_Ellis['ellis-load.avg_1_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "5oQK-ddinvCM",
    "outputId": "a611220f-df65-4d99-9c8f-dc0dd715f93f"
   },
   "outputs": [],
   "source": [
    "## ## using multivariate feature \n",
    "\n",
    "features_3 = ['ellis-cpu.wait_perc', 'ellis-load.avg_1_min', 'ellis-net.in_bytes_sec', 'Label']\n",
    "\n",
    "features = df_Ellis[features_3]\n",
    "features.index = df_Ellis['Timestamp']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "qbqn755fo81g",
    "outputId": "8750fe62-a1e7-40ca-a3c1-4285546f97ff"
   },
   "outputs": [],
   "source": [
    "features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJQD1x9psWCH"
   },
   "outputs": [],
   "source": [
    "features = features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xf8WCiykpUzN",
    "outputId": "b43752ab-2ff0-4e21-a4bc-633cd0aff7dd"
   },
   "outputs": [],
   "source": [
    "### standardize data\n",
    "train_split = 141600\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "### standardize data\n",
    "features_mean = features[:train_split].mean()\n",
    "features_std = features[:train_split].std()\n",
    "features  = (features - features_mean)/ features_std\n",
    "\n",
    "print(type(features))\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a0hNDmppnLB"
   },
   "outputs": [],
   "source": [
    "### create mutlivariate data\n",
    "\n",
    "def mutlivariate_data(features , target , start_idx , end_idx , history_size , target_size,\n",
    "                      step ,  single_step = False):\n",
    "  data = []\n",
    "  labels = []\n",
    "  start_idx = start_idx + history_size\n",
    "  if end_idx is None:\n",
    "    end_idx = len(features)- target_size\n",
    "  for i in range(start_idx , end_idx ):\n",
    "    idxs = range(i-history_size, i, step) ### using step\n",
    "    data.append(features[idxs])\n",
    "    if single_step:\n",
    "      labels.append(target[i+target_size])\n",
    "    else:\n",
    "      labels.append(target[i:i+target_size])\n",
    "\n",
    "  return np.array(data) , np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0CivgkitfgE",
    "outputId": "614149cc-6746-4d02-a608-2957cef79338"
   },
   "outputs": [],
   "source": [
    "### generate multivariate data\n",
    "\n",
    "history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "x_train_ss , y_train_ss = mutlivariate_data(features , features[:, 1], 0, train_split, history,\n",
    "                                            future_target, STEP , single_step = True)\n",
    "\n",
    "x_val_ss , y_val_ss = mutlivariate_data(features , features[:,1] , train_split , None , history ,\n",
    "                                        future_target, STEP, single_step = True)\n",
    "\n",
    "print(x_train_ss.shape , y_train_ss.shape)\n",
    "print(x_val_ss.shape , y_val_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBdr2epGu3aq",
    "outputId": "f9dc4c4f-ccfa-4379-add5-cd732dc8a310"
   },
   "outputs": [],
   "source": [
    "## tensorflow dataset\n",
    "batch_size = 256\n",
    "buffer_size = 10000\n",
    "\n",
    "train_ss = tf.data.Dataset.from_tensor_slices((x_train_ss, y_train_ss))\n",
    "train_ss = train_ss.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "val_ss = tf.data.Dataset.from_tensor_slices((x_val_ss, y_val_ss))\n",
    "val_ss = val_ss.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "print(train_ss)\n",
    "print(val_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eQpwUyGglu_"
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81S0BbNa7Rce"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Activation, Dense, Dropout,Permute,Reshape,Lambda,dot,concatenate\n",
    "\n",
    "INPUT_DIM = 100\n",
    "TIME_STEPS = 20\n",
    "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "SINGLE_ATTENTION_VECTOR = True\n",
    "APPLY_ATTENTION_BEFORE_LSTM = False\n",
    "\n",
    "ATTENTION_SIZE = 128\n",
    "\n",
    "def attention_3d_block(hidden_states):\n",
    "    # hidden_states.shape = (batch_size, time_steps, hidden_size)\n",
    "    hidden_size = int(hidden_states.shape[2])\n",
    "    # _t stands for transpose\n",
    "    hidden_states_t =  Permute((2, 1), name='attention_input_t')(hidden_states)\n",
    "    # hidden_states_t.shape = (batch_size, hidden_size, time_steps)\n",
    "    # this line is not useful. It's just to know which dimension is what.\n",
    "    hidden_states_t = Reshape((hidden_size, TIME_STEPS), name='attention_input_reshape')(hidden_states_t)\n",
    "    # Inside dense layer\n",
    "    # a (batch_size, hidden_size, time_steps) dot W (time_steps, time_steps) => (batch_size, hidden_size, time_steps)\n",
    "    # W is the trainable weight matrix of attention\n",
    "    # Luong's multiplicative style score\n",
    "    score_first_part = Dense(TIME_STEPS, use_bias=False, name='attention_score_vec')(hidden_states_t)\n",
    "    score_first_part_t = Permute((2, 1), name='attention_score_vec_t')(score_first_part)\n",
    "    #            score_first_part_t         dot        last_hidden_state     => attention_weights\n",
    "    # (batch_size, time_steps, hidden_size) dot (batch_size, hidden_size, 1) => (batch_size, time_steps, 1)\n",
    "    h_t = Lambda(lambda x: x[:, :, -1], output_shape=(hidden_size, 1), name='last_hidden_state')(hidden_states_t)\n",
    "    score = dot([score_first_part_t, h_t], [2, 1], name='attention_score')\n",
    "    attention_weights = Activation('softmax', name='attention_weight')(score)\n",
    "    # if SINGLE_ATTENTION_VECTOR:\n",
    "    #     a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    #     a = RepeatVector(hidden_size)(a)\n",
    "    # (batch_size, hidden_size, time_steps) dot (batch_size, time_steps, 1) => (batch_size, hidden_size, 1)\n",
    "    context_vector = dot([hidden_states_t, attention_weights], [2, 1], name='context_vector')\n",
    "    context_vector = Reshape((hidden_size,))(context_vector)\n",
    "    h_t = Reshape((hidden_size,))(h_t)\n",
    "    pre_activation = concatenate([context_vector, h_t], name='attention_output')\n",
    "    attention_vector = Dense(ATTENTION_SIZE, use_bias=False, activation='tanh', name='attention_vector')(pre_activation)\n",
    "    return attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cKtTAzqyiyL",
    "outputId": "e1863cec-a19f-4419-fe8c-527e549bccdf"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers import Input, LSTM, merge ,Conv1D,Dropout,Bidirectional,Multiply,Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "### Modelling using LSTM\n",
    "steps = 50\n",
    "TIME_STEPS=120\n",
    "INPUT_DIMS=4\n",
    "\n",
    "EPOCHS =20\n",
    "\n",
    "single_step_model = tf.keras.models.Sequential()\n",
    "\n",
    "inputs = Input(shape=(120, 4))\n",
    "lstm_units = 32\n",
    "lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "lstm_out=tf.keras.layers.Dropout(0.6)(lstm_out)\n",
    "attention_mul = attention_3d_block(lstm_out)\n",
    "#attention_mul = Flatten()(attention_mul)\n",
    "attention_mul=tf.keras.layers.Dropout(0.6)(attention_mul)\n",
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "\n",
    "single_step_model = Model(inputs, output)\n",
    "\n",
    "  \n",
    "single_step_model.summary()\n",
    "\n",
    "plot_model(single_step_model, to_file='/content/drive/MyDrive/LFN Anuket/Analysis/data/Final/LSTM-Attention-B.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "single_step_model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mae',metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#single_step_model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94000u5xIjWD",
    "outputId": "c3f7f857-fbb7-4fc5-b2bf-d860a828d0a9"
   },
   "outputs": [],
   "source": [
    "single_step_model_history = single_step_model.fit(train_ss, epochs = EPOCHS , \n",
    "                                                  steps_per_epoch =steps, validation_data = val_ss,\n",
    "                                                  validation_steps = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Pgev0dgzzBVx",
    "outputId": "a97e1688-da30-4042-c349-fa8971512907"
   },
   "outputs": [],
   "source": [
    "## plot train test loss \n",
    "\n",
    "def plot_loss(history , title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss , 'b' , label = 'Train Loss')\n",
    "  plt.plot(epochs, val_loss , 'r' , label = 'Validation Loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "\n",
    "plot_loss(single_step_model_history , 'Single Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "EnYf6j4okEoC",
    "outputId": "be978504-7501-42fe-c192-4c6b023e992a"
   },
   "outputs": [],
   "source": [
    "## plot train test loss \n",
    "\n",
    "def plot_loss(history , title):\n",
    "  loss = history.history['rmse']\n",
    "  val_loss = history.history['val_rmse']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss , 'b' , label = 'Train RMSE')\n",
    "  plt.plot(epochs, val_loss , 'r' , label = 'Validation RMSE')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "\n",
    "plot_loss(single_step_model_history , 'Single Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMegV8mNAwe_"
   },
   "outputs": [],
   "source": [
    "### fucntion to create time steps\n",
    "def create_time_steps(length):\n",
    "  return list(range(-length,0))\n",
    "\n",
    "### function to plot time series data\n",
    "\n",
    "def plot_time_series(plot_data, delta , title):\n",
    "  labels = [\"History\" , 'True Future' , 'Model Predcited']\n",
    "  marker = ['.-' , 'rx' , 'go']\n",
    "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "\n",
    "  if delta:\n",
    "    future = delta\n",
    "  else:\n",
    "    future = 0\n",
    "  plt.title(title)\n",
    "  for i , x in enumerate(plot_data):\n",
    "    if i :\n",
    "      plt.plot(future , plot_data[i] , marker[i], markersize = 10 , label = labels[i])\n",
    "    else:\n",
    "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label = labels[i])\n",
    "  plt.legend()\n",
    "  plt.xlim([time_steps[0], (future+5) *2])\n",
    "\n",
    "  plt.xlabel('Time_Step')\n",
    "  return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q99i2c-9XKF3"
   },
   "outputs": [],
   "source": [
    "### Moving window average\n",
    "\n",
    "def MWA(history):\n",
    "  return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xFJT1rZDAUVL",
    "outputId": "56ae677f-dadd-434f-f31b-d7cc9ee0eb89"
   },
   "outputs": [],
   "source": [
    "# plot time series and predicted values\n",
    "\n",
    "for x, y in val_ss.take(5):\n",
    "  plot = plot_time_series([x[0][:, 1].numpy(), y[0].numpy(),\n",
    "                    single_step_model.predict(x)[0]], 12,\n",
    "                   'Single Step Prediction')\n",
    "  plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KXWQVmyCSix"
   },
   "source": [
    "# **MultiStep Forcasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lu7m2Rr4AbMK",
    "outputId": "9436a6eb-214e-47a3-d241-3a5bd056c31c"
   },
   "outputs": [],
   "source": [
    "future_target = 72 # 72 future values\n",
    "x_train_multi, y_train_multi = mutlivariate_data(features, features[:, 1], 0,\n",
    "                                                 train_split, history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = mutlivariate_data(features, features[:, 1],\n",
    "                                             train_split, None, history,\n",
    "                                             future_target, STEP)\n",
    "\n",
    "print(x_train_multi.shape)\n",
    "print(y_train_multi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLRv5D16CrHj"
   },
   "outputs": [],
   "source": [
    "#  TF DATASET\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(batch_size).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjXexah9C8yg",
    "outputId": "185bb543-b7ad-4f25-fd89-75be524af04e"
   },
   "outputs": [],
   "source": [
    "print(train_data_multi)\n",
    "print(val_data_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "7mtLZ6S-DPU-",
    "outputId": "553066ce-28bf-4e95-95c1-f7f34f907647"
   },
   "outputs": [],
   "source": [
    "#plotting function\n",
    "def multi_step_plot(history, true_future, prediction):\n",
    "  plt.figure(figsize=(12, 6))\n",
    "  num_in = create_time_steps(len(history))\n",
    "  num_out = len(true_future)\n",
    "  plt.grid()\n",
    "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "  if prediction.any():\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "             label='Predicted Future')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "\n",
    "for x, y in train_data_multi.take(1):\n",
    "  multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snN_Flr5DWQN",
    "outputId": "8c9fb49d-7743-4966-845b-f56a06bbe9e6"
   },
   "outputs": [],
   "source": [
    "multi_step_model = tf.keras.models.Sequential()\n",
    "\n",
    "inputs = Input(shape=(120, 4))\n",
    "lstm_units = 32\n",
    "lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "lstm_out=tf.keras.layers.Dropout(0.6)(lstm_out)\n",
    "attention_mul = attention_3d_block(lstm_out)\n",
    "#attention_mul = Flatten()(attention_mul)\n",
    "attention_mul=tf.keras.layers.Dropout(0.6)(attention_mul)\n",
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "\n",
    "multi_step_model = Model(inputs, output)\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae',metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=steps,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=50)\n",
    "multi_step_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay5m27doDsTt",
    "outputId": "e9e4b8ea-77d6-438f-9698-91b95180e6f2"
   },
   "outputs": [],
   "source": [
    "plot_loss(multi_step_history, 'Multi-Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZFP49W4D2wp",
    "outputId": "41c0548f-3fd9-41eb-b2c8-045ec24f59c3"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(5):\n",
    "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNKMjVoAVqZP"
   },
   "outputs": [],
   "source": [
    "scores = multi_step_model.evaluate(x_train_multi, y_train_multi, verbose=1, batch_size=200)\n",
    "print('MAE: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXcsNZ8yu9Ay"
   },
   "outputs": [],
   "source": [
    "scores_test = multi_step_model.evaluate(x_val_multi, y_val_multi, verbose=1, batch_size=200)\n",
    "print('MAE: {}'.format(scores[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCFgbZEOvZ9A"
   },
   "outputs": [],
   "source": [
    "y_pred_test = multi_step_model.predict(x_val_multi, verbose=0)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(y_pred_test)\n",
    "plt.plot(y_val_multi)\n",
    "plt.ylabel(\"RUL\")\n",
    "plt.xlabel(\"Unit Number\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Pdu1pZyZExX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
